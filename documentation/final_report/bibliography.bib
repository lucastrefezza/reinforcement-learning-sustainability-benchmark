@misc{mnih:atari,
	title={Playing Atari with Deep Reinforcement Learning}, 
	author={Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Alex Graves and Ioannis Antonoglou and Daan Wierstra and Martin Riedmiller},
	year={2013},
	eprint={1312.5602},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/1312.5602}, 
}

@article{mnih:human,
	title={Human-level control through deep reinforcement learning},
	author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
	journal={nature},
	volume={518},
	number={7540},
	pages={529--533},
	year={2015},
	publisher={Nature Publishing Group UK London}
}

@inproceedings{hessel:rainbow,
	title={Rainbow: Combining improvements in deep reinforcement learning},
	author={Hessel, Matteo and Modayil, Joseph and Van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
	booktitle={Proceedings of the AAAI conference on artificial intelligence},
	volume={32},
	number={1},
	year={2018}
}

@article{van:double_q,
	title={Deep reinforcement learning with double Q-learning},
	author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
	journal={arXiv preprint arXiv:1509.06461},
	year={2016}
}

@article{schaul:prioritized,
	title={Prioritized experience replay},
	author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
	journal={arXiv preprint arXiv:1511.05952},
	year={2015}
}

@article{wang:dueling,
	title={Dueling network architectures for deep reinforcement learning},
	author={Wang, Ziyu and Schaul, Tom and Hessel, Matteo and Van Hasselt, Hado and Lanctot, Marc and De Freitas, Nando},
	journal={arXiv preprint arXiv:1511.06581},
	year={2015}
}

@inproceedings{peng:incremental,
	title={Incremental multi-step Q-learning},
	author={Peng, Jing and Williams, Ronald J},
	booktitle={Machine Learning Proceedings 1994},
	pages={226--232},
	year={1994},
	organization={Elsevier}
}

@article{bellemare:distributional,
	title={A distributional perspective on reinforcement learning},
	author={Bellemare, Marc G and Dabney, Will and Munos, Remi},
	journal={arXiv preprint arXiv:1707.06887},
	year={2017}
}

@article{fortunato:noisy,
	title={Noisy networks for exploration},
	author={Fortunato, Meire and Azar, Mohammad Gheshlaghi and Piot, Bilal and Menick, Jacob and Osband, Ian and Graves, Alex and Mnih, Vlad and Munos, Remi and Hassabis, Demis and Pietquin, Olivier and others},
	journal={arXiv preprint arXiv:1706.10295},
	year={2017}
}

@book{sutton:rl,
	title={Reinforcement learning: An introduction},
	author={Sutton, Richard S and Barto, Andrew G},
	year={2018},
	publisher={MIT press}
}

@article{kostrikov:drq,
	title={Image augmentation is all you need: Regularizing deep reinforcement learning from pixels},
	author={Kostrikov, Ilya and Yarats, Denis and Fergus, Rob},
	journal={arXiv preprint arXiv:2004.13649},
	year={2020}
}

@article{schwarzer:spr,
	title={Data-efficient reinforcement learning with self-predictive representations},
	author={Schwarzer, Max and Anand, Ankesh and Goel, Rishab and Hjelm, R Devon and Courville, Aaron and Bachman, Philip},
	journal={arXiv preprint arXiv:2007.05929},
	year={2020}
}

@article{schulman:ppo,
	title={Proximal policy optimization algorithms},
	author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
	journal={arXiv preprint arXiv:1707.06347},
	year={2017}
}

@inproceedings{fujimoto:td3,
	title={Addressing function approximation error in actor-critic methods},
	author={Fujimoto, Scott and Hoof, Herke and Meger, David},
	booktitle={International Conference on Machine Learning},
	pages={1587--1596},
	year={2018},
	organization={PMLR}
}

@misc{lillicrap:ddpg,
	title={Continuous control with deep reinforcement learning}, 
	author={Timothy P. Lillicrap and Jonathan J. Hunt and Alexander Pritzel and Nicolas Heess and Tom Erez and Yuval Tassa and David Silver and Daan Wierstra},
	year={2019},
	eprint={1509.02971},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/1509.02971}, 
}

@misc{haarnoja:sac,
	title={Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor}, 
	author={Tuomas Haarnoja and Aurick Zhou and Pieter Abbeel and Sergey Levine},
	year={2018},
	eprint={1801.01290},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/1801.01290}, 
}

@article{bellemare:ale,
	title={The Arcade Learning Environment: An Evaluation Platform for General Agents},
	volume={47},
	ISSN={1076-9757},
	url={http://dx.doi.org/10.1613/jair.3912},
	DOI={10.1613/jair.3912},
	journal={Journal of Artificial Intelligence Research},
	publisher={AI Access Foundation},
	author={Bellemare, M. G. and Naddaf, Y. and Veness, J. and Bowling, M.},
	year={2013},
	month=jun, pages={253–279}
}

@article{machado:revisiting_ale,
	title={Revisiting the arcade learning environment: Evaluation protocols and open problems for general agents},
	author={Machado, Marlos C and Bellemare, Marc G and Talvitie, Erik and Veness, Joel and Hausknecht, Matthew and Bowling, Michael},
	journal={Journal of Artificial Intelligence Research},
	volume={61},
	pages={523--562},
	year={2018}
}

@misc{farama:ale,
	author       = "{Farama Foundation}",
	title        = "{Arcade Learning Environment (ALE) Environments}",
	year         = {2025},
	url          = {https://ale.farama.org/environments/},
	note         = "Accessed: 2025-02-06"
}

@misc{agarwal:statistical_precipice,
	title={Deep Reinforcement Learning at the Edge of the Statistical Precipice}, 
	author={Rishabh Agarwal and Max Schwarzer and Pablo Samuel Castro and Aaron Courville and Marc G. Bellemare},
	year={2022},
	eprint={2108.13264},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/2108.13264}, 
}

@misc{kaiser:atari100k,
	title={Model-Based Reinforcement Learning for Atari}, 
	author={Lukasz Kaiser and Mohammad Babaeizadeh and Piotr Milos and Blazej Osinski and Roy H Campbell and Konrad Czechowski and Dumitru Erhan and Chelsea Finn and Piotr Kozakowski and Sergey Levine and Afroz Mohiuddin and Ryan Sepassi and George Tucker and Henryk Michalewski},
	year={2024},
	eprint={1903.00374},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/1903.00374}, 
}

@misc{huang:cleanrl,
	author  = {Shengyi Huang and Rousslan Fernand Julien Dossa and Chang Ye and Jeff Braga and Dipam Chakraborty and Kinal Mehta and João G.M. Araújo},
	title   = {CleanRL: High-quality Single-file Implementations of Deep Reinforcement Learning Algorithms},
	journal = {Journal of Machine Learning Research},
	year    = {2022},
	volume  = {23},
	number  = {274},
	pages   = {1--18},
	url     = {http://jmlr.org/papers/v23/21-1342.html}
}

@software{benoit:code_carbon,
	author       = {Benoit Courty and
	Victor Schmidt and
	Sasha Luccioni and
	Goyal-Kamal and
	MarionCoutarel and
	Boris Feld and
	Jérémy Lecourt and
	LiamConnell and
	Amine Saboni and
	Inimaz and
	supatomic and
	Mathilde Léval and
	Luis Blanche and
	Alexis Cruveiller and
	ouminasara and
	Franklin Zhao and
	Aditya Joshi and
	Alexis Bogroff and
	Hugues de Lavoreille and
	Niko Laskaris and
	Edoardo Abati and
	Douglas Blank and
	Ziyao Wang and
	Armin Catovic and
	Marc Alencon and
	Michał Stęchły and
	Christian Bauer and
	Lucas Otávio N. de Araújo and
	JPW and
	MinervaBooks},
	title        = {mlco2/codecarbon: v2.4.1},
	month        = may,
	year         = 2024,
	publisher    = {Zenodo},
	version      = {v2.4.1},
	doi          = {10.5281/zenodo.11171501},
	url          = {https://doi.org/10.5281/zenodo.11171501}
}

@misc{schulman:gae,
	title={High-Dimensional Continuous Control Using Generalized Advantage Estimation}, 
	author={John Schulman and Philipp Moritz and Sergey Levine and Michael Jordan and Pieter Abbeel},
	year={2018},
	eprint={1506.02438},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/1506.02438}, 
}

@misc{deepseekai:r1,
	title={DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning}, 
	author={DeepSeek-AI and Daya Guo and Dejian Yang and Haowei Zhang and Junxiao Song and Ruoyu Zhang and Runxin Xu and Qihao Zhu and Shirong Ma and Peiyi Wang and Xiao Bi and Xiaokang Zhang and Xingkai Yu and Yu Wu and Z. F. Wu and Zhibin Gou and Zhihong Shao and Zhuoshu Li and Ziyi Gao and Aixin Liu and Bing Xue and Bingxuan Wang and Bochao Wu and Bei Feng and Chengda Lu and Chenggang Zhao and Chengqi Deng and Chenyu Zhang and Chong Ruan and Damai Dai and Deli Chen and Dongjie Ji and Erhang Li and Fangyun Lin and Fucong Dai and Fuli Luo and Guangbo Hao and Guanting Chen and Guowei Li and H. Zhang and Han Bao and Hanwei Xu and Haocheng Wang and Honghui Ding and Huajian Xin and Huazuo Gao and Hui Qu and Hui Li and Jianzhong Guo and Jiashi Li and Jiawei Wang and Jingchang Chen and Jingyang Yuan and Junjie Qiu and Junlong Li and J. L. Cai and Jiaqi Ni and Jian Liang and Jin Chen and Kai Dong and Kai Hu and Kaige Gao and Kang Guan and Kexin Huang and Kuai Yu and Lean Wang and Lecong Zhang and Liang Zhao and Litong Wang and Liyue Zhang and Lei Xu and Leyi Xia and Mingchuan Zhang and Minghua Zhang and Minghui Tang and Meng Li and Miaojun Wang and Mingming Li and Ning Tian and Panpan Huang and Peng Zhang and Qiancheng Wang and Qinyu Chen and Qiushi Du and Ruiqi Ge and Ruisong Zhang and Ruizhe Pan and Runji Wang and R. J. Chen and R. L. Jin and Ruyi Chen and Shanghao Lu and Shangyan Zhou and Shanhuang Chen and Shengfeng Ye and Shiyu Wang and Shuiping Yu and Shunfeng Zhou and Shuting Pan and S. S. Li and Shuang Zhou and Shaoqing Wu and Shengfeng Ye and Tao Yun and Tian Pei and Tianyu Sun and T. Wang and Wangding Zeng and Wanjia Zhao and Wen Liu and Wenfeng Liang and Wenjun Gao and Wenqin Yu and Wentao Zhang and W. L. Xiao and Wei An and Xiaodong Liu and Xiaohan Wang and Xiaokang Chen and Xiaotao Nie and Xin Cheng and Xin Liu and Xin Xie and Xingchao Liu and Xinyu Yang and Xinyuan Li and Xuecheng Su and Xuheng Lin and X. Q. Li and Xiangyue Jin and Xiaojin Shen and Xiaosha Chen and Xiaowen Sun and Xiaoxiang Wang and Xinnan Song and Xinyi Zhou and Xianzu Wang and Xinxia Shan and Y. K. Li and Y. Q. Wang and Y. X. Wei and Yang Zhang and Yanhong Xu and Yao Li and Yao Zhao and Yaofeng Sun and Yaohui Wang and Yi Yu and Yichao Zhang and Yifan Shi and Yiliang Xiong and Ying He and Yishi Piao and Yisong Wang and Yixuan Tan and Yiyang Ma and Yiyuan Liu and Yongqiang Guo and Yuan Ou and Yuduan Wang and Yue Gong and Yuheng Zou and Yujia He and Yunfan Xiong and Yuxiang Luo and Yuxiang You and Yuxuan Liu and Yuyang Zhou and Y. X. Zhu and Yanhong Xu and Yanping Huang and Yaohui Li and Yi Zheng and Yuchen Zhu and Yunxian Ma and Ying Tang and Yukun Zha and Yuting Yan and Z. Z. Ren and Zehui Ren and Zhangli Sha and Zhe Fu and Zhean Xu and Zhenda Xie and Zhengyan Zhang and Zhewen Hao and Zhicheng Ma and Zhigang Yan and Zhiyu Wu and Zihui Gu and Zijia Zhu and Zijun Liu and Zilin Li and Ziwei Xie and Ziyang Song and Zizheng Pan and Zhen Huang and Zhipeng Xu and Zhongyu Zhang and Zhen Zhang},
	year={2025},
	eprint={2501.12948},
	archivePrefix={arXiv},
	primaryClass={cs.CL},
	url={https://arxiv.org/abs/2501.12948}, 
}

@misc{ahmadian:back_to_basics,
	title={Back to Basics: Revisiting REINFORCE Style Optimization for Learning from Human Feedback in LLMs}, 
	author={Arash Ahmadian and Chris Cremer and Matthias Gallé and Marzieh Fadaee and Julia Kreutzer and Olivier Pietquin and Ahmet Üstün and Sara Hooker},
	year={2024},
	eprint={2402.14740},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/2402.14740}, 
}

@misc{wang:rl_enhanced_llm,
	title={Reinforcement Learning Enhanced LLMs: A Survey}, 
	author={Shuhe Wang and Shengyu Zhang and Jie Zhang and Runyi Hu and Xiaoya Li and Tianwei Zhang and Jiwei Li and Fei Wu and Guoyin Wang and Eduard Hovy},
	year={2025},
	eprint={2412.10400},
	archivePrefix={arXiv},
	primaryClass={cs.CL},
	url={https://arxiv.org/abs/2412.10400}, 
}

@misc{pan:tinyzero,
	author       = {Jiayi Pan},
	title        = {TinyZero},
	year         = {2024},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/Jiayi-Pan/TinyZero}},
	note         = {Accessed: 2025-02-25}
}